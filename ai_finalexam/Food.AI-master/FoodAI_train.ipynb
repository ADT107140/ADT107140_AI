{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/jonathanyin12/Food.AI/blob/master/FoodAI_train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V4123YVhoK3i"
   },
   "source": [
    "# **Food.AI Training Notebook**\n",
    "Easy calorie tracking using real-time object detection on Android. \n",
    "\n",
    "**[GitHub](https://github.com/jonathanyin12/Food.AI)**\n",
    "\n",
    "### **Instructions**:\n",
    "* Prior to starting, create a directory in Google Drive called *food_detection*. Add the **[training dataset](https://drive.google.com/file/d/11WC6XPp4kHGN1vEzl_ZRnFla99pxIs33/view)** and **[label_map.pbtxt](https://github.com/jonathanyin12/Food.AI/blob/master/label_map.pbtxt)** to *food_detection*.\n",
    "\n",
    "* Make sure runtime is set to use GPU acceleration\n",
    "\n",
    "* After installing the correct version of NumPy, restart the runtime and run all the cells after.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 372
    },
    "colab_type": "code",
    "id": "rCXvr-0MSivk",
    "outputId": "7039397d-9154-453c-cac1-2463b7f32458"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Dec 27 20:30:31 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 398.35                 Driver Version: 398.35                    |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce GTX 1050   WDDM  | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   33C    P0    N/A /  N/A |     75MiB /  4096MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# Checking gpu\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8kvLE33UNCag"
   },
   "source": [
    "### **Installing Dependencies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "colab_type": "code",
    "id": "RHFbvc0TV8Yc",
    "outputId": "d16ab71d-d9ac-4596-af8c-9687c15ee894"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy==1.17.4\n",
      "  Downloading numpy-1.17.4-cp38-cp38-win_amd64.whl (12.7 MB)\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.19.2\n",
      "    Uninstalling numpy-1.19.2:\n",
      "      Successfully uninstalled numpy-1.19.2\n",
      "Successfully installed numpy-1.17.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: After October 2020 you may experience errors when installing or updating packages. This is because pip will change the way that it resolves dependency conflicts.\n",
      "\n",
      "We recommend you use --use-feature=2020-resolver to test your packages with the new resolver before it becomes the default.\n",
      "\n",
      "tensorflow 2.4.0 requires numpy~=1.19.2, but you'll have numpy 1.17.4 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "# IMPORTANT: make sure to restart runtime after running this cell\n",
    "!pip install numpy==1.17.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 407
    },
    "colab_type": "code",
    "id": "dIoahiCWSJb0",
    "outputId": "ca6f1b8a-391f-445f-9e8a-f89a7f930dbf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%tensorflow_version` not found.\n"
     ]
    }
   ],
   "source": [
    "%tensorflow_version 1.x\n",
    "\n",
    "!git clone --quiet https://github.com/tensorflow/models.git # download training tools\n",
    "\n",
    "!wget http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v2_coco_2018_03_29.tar.gz # download model\n",
    "!tar xvzf ssd_mobilenet_v2_coco_2018_03_29.tar.gz\n",
    " \n",
    "!git clone --quiet https://github.com/zamblauskas/oidv4-toolkit-tfrecord-generator.git # download tfrecord generator tool\n",
    "\n",
    "!apt-get install -qq protobuf-compiler python-tk\n",
    "\n",
    "!pip install -q Cython contextlib2 pillow lxml matplotlib PyDrive pycocotools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 301
    },
    "colab_type": "code",
    "id": "c6d3ccbPSN6G",
    "outputId": "212485ab-8a57-4c71-cd3f-e243aa763741"
   },
   "outputs": [],
   "source": [
    "%cd /content/models/research\n",
    "!protoc object_detection/protos/*.proto --python_out=.\n",
    "!python setup.py -q build\n",
    "!python setup.py -q install\n",
    "\n",
    "import os\n",
    "os.environ['PYTHONPATH'] += '/content/models/research/:/content/models/research/slim/'\n",
    "\n",
    "%cd /content/models/research/slim\n",
    "!pip install -e .\n",
    "\n",
    "%cd /content/models/research\n",
    "!python object_detection/builders/model_builder_test.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_VhAQOrINKqy"
   },
   "source": [
    "### **Load food dataset and label map from Drive**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "EuI0mMxJOb2h",
    "outputId": "eaa622d7-e794-4e87-d392-7875224c76e5"
   },
   "outputs": [],
   "source": [
    "%cd /content/\n",
    "\n",
    "from google.colab import drive\n",
    "from zipfile import ZipFile\n",
    "from shutil import copyfile\n",
    "\n",
    "drive.mount('/content/gdrive')\n",
    "copyfile('/content/gdrive/My Drive/food_detection/label_map.pbtxt', 'label_map.pbtxt')\n",
    "\n",
    "data_path='/content/gdrive/My Drive/food_detection/OIDv4_ToolKit.zip'\n",
    "with ZipFile(data_path, 'r') as zipObj:\n",
    "    zipObj.extractall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GqQQ7uGQNh4u"
   },
   "source": [
    "### **Convert dataset into TFRecords format**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 641
    },
    "colab_type": "code",
    "id": "OjS_ckYPOaZV",
    "outputId": "dbe943ac-f843-460d-c917-3828c8f3e283"
   },
   "outputs": [],
   "source": [
    "!python oidv4-toolkit-tfrecord-generator/generate-tfrecord.py \\\n",
    "    --classes_file=OIDv4_ToolKit/classes.txt \\\n",
    "    --class_descriptions_file=OIDv4_ToolKit/OID/csv_folder/class-descriptions-boxable.csv \\\n",
    "    --annotations_file=OIDv4_ToolKit/OID/csv_folder/train-annotations-bbox.csv \\\n",
    "    --images_dir=OIDv4_ToolKit/OID/Dataset/train \\\n",
    "    --output_file=train.record\n",
    "\n",
    "!python oidv4-toolkit-tfrecord-generator/generate-tfrecord.py \\\n",
    "    --classes_file=OIDv4_ToolKit/classes.txt \\\n",
    "    --class_descriptions_file=OIDv4_ToolKit/OID/csv_folder/class-descriptions-boxable.csv \\\n",
    "    --annotations_file=OIDv4_ToolKit/OID/csv_folder/validation-annotations-bbox.csv \\\n",
    "    --images_dir=OIDv4_ToolKit/OID/Dataset/validation \\\n",
    "    --output_file=val.record"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l_rDls2EgQlR"
   },
   "source": [
    "### **Edit model configuration files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wbutwvfdINn-"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "filename = '/content/models/research/object_detection/samples/configs/ssd_mobilenet_v2_coco.config'\n",
    "with open(filename) as f:\n",
    "    s = f.read()\n",
    "with open(filename, 'w') as f:\n",
    "    s = re.sub('90', '15', s) # change number of classes from 90 to 15\n",
    "    s = re.sub('PATH_TO_BE_CONFIGURED/model.ckpt', '/content/ssd_mobilenet_v2_coco_2018_03_29/model.ckpt', s) # pass location of model checkpoint\n",
    "    s = re.sub('PATH_TO_BE_CONFIGURED/mscoco_train.record-\\?\\?\\?\\?\\?-of-00100', '/content/train.record', s) # pass location of train tfrecod\n",
    "    s = re.sub('PATH_TO_BE_CONFIGURED/mscoco_val.record-\\?\\?\\?\\?\\?-of-00010', '/content/val.record', s) # pass location of validation tfrecord\n",
    "    s = re.sub('PATH_TO_BE_CONFIGURED/mscoco_label_map.pbtxt', '/content/label_map.pbtxt', s) # pass location of label map\n",
    "\n",
    "    f.write(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6-wLScivf5-x"
   },
   "source": [
    "### **Train model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "both",
    "colab": {},
    "colab_type": "code",
    "id": "T_XfV1HTQp_f"
   },
   "outputs": [],
   "source": [
    "!python models/research/object_detection/model_main.py \\\n",
    "    --pipeline_config_path=/content/models/research/object_detection/samples/configs/ssd_mobilenet_v2_coco.config \\\n",
    "    --model_dir=/content/gdrive/My\\ Drive/food_detection/model_checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tD0SbAMjmjsT"
   },
   "source": [
    "### **Export model to frozen TensorFlow Lite graph**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DIM3xJw2HkyO"
   },
   "outputs": [],
   "source": [
    "lst = os.listdir('/content/gdrive/My Drive/food_detection/model_checkpoints')\n",
    "lf = filter(lambda k: 'model.ckpt-' in k, lst)\n",
    "last_model = sorted(lf)[-1].replace('.meta', '')\n",
    "\n",
    "!python /content/models/research/object_detection/export_tflite_ssd_graph.py \\\n",
    "    --pipeline_config_path=/content/models/research/object_detection/samples/configs/ssd_mobilenet_v2_coco.config \\\n",
    "    --trained_checkpoint_prefix=/content/gdrive/My\\ Drive/food_detection/model_checkpoints/$last_model \\\n",
    "    --output_directory=/content/gdrive/My\\ Drive/food_detection/model_checkpoints/tflite_model \\\n",
    "    --add_postprocessing_op=true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6m_Mxhbgm02f"
   },
   "source": [
    "### **Convert the frozen graph to a TFLite model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tOPsn-TjQvZv"
   },
   "outputs": [],
   "source": [
    "%cd /content/gdrive/My\\ Drive/food_detection/model_checkpoints/tflite_model\n",
    "\n",
    "!tflite_convert \\\n",
    "    --output_file=food_detect.tflite \\\n",
    "    --graph_def_file=tflite_graph.pb \\\n",
    "    --input_arrays=normalized_input_image_tensor \\\n",
    "    --output_arrays='TFLite_Detection_PostProcess','TFLite_Detection_PostProcess:1','TFLite_Detection_PostProcess:2','TFLite_Detection_PostProcess:3'\\\n",
    "    --input_shape=1,300,300,3 \\\n",
    "    --allow_custom_ops"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNVM38Lod8YONgkO006ez29",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "FoodAI_train.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
